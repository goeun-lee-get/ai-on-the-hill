{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fatty-turkey",
   "metadata": {},
   "source": [
    "# Going Deeper 6. Go/Stop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "infrared-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import copy\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-criticism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 11.71 GiB (download: 11.71 GiB, generated: 5.27 GiB, total: 16.98 GiB) to /home/aiffel-dj3/tensorflow_datasets/kitti/3.2.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a991e02b9142c1bcaf6223712b9a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: |          | 0/0 [00:00<?, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818005b044c84d368c5821c2500f30b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: |          | 0/0 [00:00<?, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 다운로드에 매우 긴 시간이 소요됩니다. \n",
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'kitti',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    with_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-theater",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = tfds.show_examples(ds_train, ds_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "individual-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "TakeDataset = ds_train.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in TakeDataset:  \n",
    "    print('------Example------')\n",
    "    print(list(example.keys())) # example is `{'image': tf.Tensor, 'label': tf.Tensor}`\n",
    "    image = example[\"image\"]\n",
    "    filename = example[\"image/file_name\"].numpy().decode('utf-8')\n",
    "    objects = example[\"objects\"]\n",
    "\n",
    "print('------objects------')\n",
    "print(objects)\n",
    "\n",
    "img = Image.fromarray(image.numpy())\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_bbox(input_image, object_bbox):\n",
    "    input_image = copy.deepcopy(input_image)\n",
    "    draw = ImageDraw.Draw(input_image)\n",
    "\n",
    "    # 바운딩 박스 좌표(x_min, x_max, y_min, y_max) 구하기\n",
    "    width, height = img.size\n",
    "    print('width:', width, ' height:', height)\n",
    "    print(object_bbox.shape)\n",
    "    x_min = object_bbox[:,1] * width\n",
    "    x_max = object_bbox[:,3] * width\n",
    "    y_min = height - object_bbox[:,0] * height\n",
    "    y_max = height - object_bbox[:,2] * height\n",
    "\n",
    "    # 바운딩 박스 그리기\n",
    "    rects = np.stack([x_min, y_min, x_max, y_max], axis=1)\n",
    "    for _rect in rects:\n",
    "        print(_rect)\n",
    "        draw.rectangle(_rect, outline=(255,0,0), width=2)\n",
    "    print(input_image)\n",
    "    return input_image\n",
    "\n",
    "visualize_bbox(img, objects['bbox'].numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-terrorism",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = os.getenv('HOME')+'/aiffel/object_detection/data'\n",
    "img_dir = os.getenv('HOME')+'/kitti_images'\n",
    "train_csv_path = data_dir + '/kitti_train.csv'\n",
    "\n",
    "# KITTI 데이터셋 ds_train을 파싱해서 dataframe으로 변환하는 parse_dataset 함수를 구현해 주세요.\n",
    "def parse_dataset(dataset, img_dir=\"kitti_images\", total=0):\n",
    "    if not os.path.exists(img_dir):\n",
    "        os.mkdir(img_dir)\n",
    "\n",
    "    type_class_map = {\n",
    "        0: \"car\",\n",
    "        1: \"car\",\n",
    "        2: \"car\",\n",
    "        3: \"person\",\n",
    "        4: \"person\",\n",
    "        5: \"person\",\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(columns=[\"img_path\", \"x1\", \"y1\", \"x2\", \"y2\", \"class_name\"])\n",
    "    for item in tqdm(dataset, total=total):\n",
    "        # 코드 구현\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = parse_dataset(ds_train, img_dir, total=ds_info.splits['train'].num_examples)\n",
    "df_train.to_csv(train_csv_path, sep=',',index = False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv_path = data_dir + '/kitti_test.csv'\n",
    "\n",
    "df_test = parse_dataset(ds_test, img_dir, total=ds_info.splits['test'].num_examples)\n",
    "df_test.to_csv(test_csv_path, sep=',',index = False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_txt_path = data_dir + '/classes.txt'\n",
    "\n",
    "def save_class_format(path=\"./classes.txt\"):\n",
    "    class_type_map = {\n",
    "        \"car\" : 0,\n",
    "        \"person\": 1\n",
    "    }\n",
    "    with open(path, mode='w', encoding='utf-8') as f:\n",
    "        for k, v in class_type_map.items():\n",
    "            f.write(f\"{k},{v}\\n\")\n",
    "\n",
    "save_class_format(class_txt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RetinaNet 훈련이 시작됩니다!! 50epoch 훈련에 1시간 이상 소요될 수 있습니다. \n",
    "!cd ~/aiffel/object_detection && python keras-retinanet/keras_retinanet/bin/train.py --gpu 0 --multiprocessing --workers 4 --batch-size 2 --epochs 50 --steps 195 csv data/kitti_train.csv data/classes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ~/aiffel/object_detection && python keras-retinanet/keras_retinanet/bin/convert_model.py snapshots/resnet50_csv_50.h5 snapshots/resnet50_csv_50_infer.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "\n",
    "# import keras_retinanet\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.models import load_model\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "from keras_retinanet.utils.gpu import setup_gpu\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "gpu = '0'\n",
    "setup_gpu(gpu)\n",
    "\n",
    "dir_path = os.getenv('HOME') + '/aiffel/object_detection/'\n",
    "model_path = os.path.join(dir_path, 'snapshots', 'resnet50_csv_50_infer.h5')\n",
    "model = load_model(model_path, backbone_name='resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = os.getenv('HOME')+'/aiffel/object_detection/test_set/stop_1.png'\n",
    "inference_on_image(model, img_path=img_path)\n",
    "\n",
    "import os\n",
    "img_path = os.getenv('HOME')+'/aiffel/object_detection/test_set/go_1.png'\n",
    "\n",
    "# inference_on_image 함수를 구현해 주세요.\n",
    "def inference_on_image(model, img_path=\"./test_set/go_1.png\", visualize=True):\n",
    "    image = read_image_bgr(img_path)\n",
    "\n",
    "    # copy to draw on\n",
    "    draw = image.copy()\n",
    "    draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    color_map = {\n",
    "        0: (0, 0, 255), # blue\n",
    "        1: (255, 0, 0) # red\n",
    "    }\n",
    "\n",
    "    # preprocess image for network\n",
    "    image = preprocess_image(image)\n",
    "    image, scale = resize_image(image)\n",
    "\n",
    "    # process image\n",
    "    boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "\n",
    "    # correct for image scale\n",
    "    boxes /= scale\n",
    "\n",
    "    # display images\n",
    "    if  visualize:\n",
    "        for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "            print(box)\n",
    "            if score < 0.5:\n",
    "                break\n",
    "            b = box.astype(int)\n",
    "            draw_box(draw, b, color=color_map[label])\n",
    "\n",
    "            caption = \"{:.3f}\".format(score)\n",
    "            draw_caption(draw, b, caption)\n",
    "\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plt.axis('off')\n",
    "        plt.imshow(draw)\n",
    "        plt.show()            \n",
    "\n",
    "inference_on_image(model, img_path=img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-turkey",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "linear-brick",
   "metadata": {},
   "source": [
    "## 프로젝트를 마치며..\n",
    "\n",
    "자율주행을 어렵게만 생각했었는데, 지금까지 배운 것들을 적용하니 비교적 쉽게 이해가 되는것 같다.\n",
    "자율주행 기반으로 많은 AI기술들을 합동하면 신기한 세상이 되겠당 ;; 내가 그 기술들을 이해하고 생산과정도 서치하여 알아갈수 있게될 생각을 해보았다. 이번 노드를 하면서 다시한번 헷갈렸던 부분이 명확해졌다. \n",
    "리스트 \n",
    "A=[1,2,3] , \n",
    "B=[3,4,5] 이라고 한다면 2행 3열이고, 이 말은 즉, 가로 3/ 세로 2가 된다는 것이다. \n",
    "간단한 것이지만 예전에 고양이 수염 붙일때 헷갈렷던 부분인데 다시한번 확인할 수 있었다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-aruba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-moderator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-guess",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-reference",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
